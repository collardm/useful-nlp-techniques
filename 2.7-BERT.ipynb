{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate creating word embeddings using BERT\n",
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 231508/231508 [00:00<00:00, 922096.77B/s]\n"
    }
   ],
   "source": [
    "# use the online model bert-base-uncased, 12/768/110M\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "30522"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# check the size of the entire vocabulary\n",
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['knight',\n 'lap',\n 'survey',\n 'ma',\n '##ow',\n 'noise',\n 'billy',\n '##ium',\n 'shooting',\n 'guide',\n 'bedroom',\n 'priest',\n 'resistance',\n 'motor',\n 'homes',\n 'sounded',\n 'giant',\n '##mer',\n '150',\n 'scenes']"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# peek at some of the vocabulary items\n",
    "list(tokenizer.vocab.keys())[5000:5020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['[CLS]',\n 'here',\n 'is',\n 'the',\n 'sentence',\n 'i',\n 'want',\n 'em',\n '##bed',\n '##ding',\n '##s',\n 'for',\n '.',\n '[SEP]']"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# [CLS] denotes start of classification\n",
    "# [SEP] is separator between sentences in a classification\n",
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "tokenized_text\n",
    "\n",
    "# note hashes in output, which means that is a subword or character of a larger word precented by another word\n",
    "# hashes split to subword tokens instead of unknowns and then average for approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['[CLS]',\n 'after',\n 'stealing',\n 'money',\n 'from',\n 'the',\n 'bank',\n 'vault',\n ',',\n 'the',\n 'bank',\n 'robber',\n 'was',\n 'seen',\n 'fishing',\n 'on',\n 'the',\n 'mississippi',\n 'river',\n 'bank',\n '.',\n '[SEP]']"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "       \"fishing on the Mississippi river bank.\"\n",
    "\n",
    "# Word2Vec classifies bank as the same meaning, BERT creates 3\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(\"[CLS] \" + text + \" [SEP]\")\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[CLS]           101\nafter         2,044\nstealing     11,065\nmoney         2,769\nfrom          2,013\nthe           1,996\nbank          2,924\nvault        11,632\n,             1,010\nthe           1,996\nbank          2,924\nrobber       27,307\nwas           2,001\nseen          2,464\nfishing       5,645\non            2,006\nthe           1,996\nmississippi   5,900\nriver         2,314\nbank          2,924\n.             1,012\n[SEP]           102\n"
    }
   ],
   "source": [
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "# tokens must be mapped to the appropriate sentence\n",
    "\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "segments_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[  101,  2044, 11065,  2769,  2013,  1996,  2924, 11632,  1010,  1996,\n          2924, 27307,  2001,  2464,  5645,  2006,  1996,  5900,  2314,  2924,\n          1012,   102]])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "tokens_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 407873900/407873900 [00:53<00:00, 7694267.09B/s]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): BertLayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): BertLayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): BertLayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): BertLayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): BertLayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): BertLayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): BertLayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): BertLayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): BertLayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): BertLayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): BertLayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): BertLayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): BertLayer(\n        (attention): BertAttention(\n          (self): BertSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): BertLayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation, less memory\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of layers:12\nNumber of batches:1\nNumber of tokens:22\nNumber of hidden units:768\n"
    }
   ],
   "source": [
    "# check on the numer of layers, batches, tokens and hidden units\n",
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "print (\"Number of batches:\", len(encoded_layers[0]))\n",
    "print (\"Number of tokens:\", len(encoded_layers[0][0]))\n",
    "print (\"Number of hidden units:\", len(encoded_layers[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Type of encoded_layers:<class 'list'>\nTensor shape for each layer:torch.Size([1, 22, 768])\n"
    }
   ],
   "source": [
    "# `encoded_layers` is a Python list.\n",
    "print('     Type of encoded_layers: ', type(encoded_layers))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', encoded_layers[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([12, 1, 22, 768])"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Concatenate the tensors for all layers. We use `stack` here to\n",
    "# create a new dimension in the tensor.\n",
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([12, 22, 768])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Remove dimension 1, the \"batches\" - that is, the sentences as we only have one\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([22, 12, 768])"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "token_embeddings.size()\n",
    "\n",
    "# token_embeddings is a [22 x 12 x 768] tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Shape is: 22 x 768\n"
    }
   ],
   "source": [
    "# Stores the token vectors, with shape [22 x 768] \n",
    "# sums the last 4 vectors\n",
    "\n",
    "# rolled up sum of tensors / vectors\n",
    "token_vecs_sum = []\n",
    "\n",
    "# token_embeddings is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    # token is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "    # Use sum_vec` to represent `token`.\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0[CLS]\n1after\n2stealing\n3money\n4from\n5the\n6bank\n7vault\n8,\n9the\n10bank\n11robber\n12was\n13seen\n14fishing\n15on\n16the\n17mississippi\n18river\n19bank\n20.\n21[SEP]\n"
    }
   ],
   "source": [
    "# reminder of the tokens\n",
    "for i, token_str in enumerate(tokenized_text):\n",
    "  print (i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "First 5 vector values for each instance of \"bank\".\nbank vaulttensor([ 2.1319, -2.1413, -1.6260,  0.8638,  3.3173])\nbank robbertensor([ 1.1868, -1.5298, -1.3770,  1.0648,  3.1446])\nriver banktensor([ 1.1295, -1.4724, -0.7296, -0.0901,  2.4970])\n"
    }
   ],
   "source": [
    "# peek at some of the embeddings\n",
    "print('First 5 vector values for each instance of \"bank\".')\n",
    "print(\"bank vault   \", str(token_vecs_sum[6][:5]))\n",
    "print(\"bank robber  \", str(token_vecs_sum[10][:5]))\n",
    "print(\"river bank   \", str(token_vecs_sum[19][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([ 2.1319e+00, -2.1413e+00, -1.6260e+00,  8.6377e-01,  3.3173e+00,\n         1.7965e-01, -4.4853e+00,  3.1215e+00, -9.7403e-01, -3.1780e+00,\n         1.0455e-01, -1.5481e+00,  4.7579e-01,  1.1703e+00, -4.4859e+00,\n         2.0283e-01,  9.5524e-01,  4.2386e+00,  4.7911e+00,  1.9296e+00,\n        -1.5251e+00, -1.4261e-01,  2.7351e+00,  1.1919e-01,  1.9293e+00,\n         6.8548e-02,  3.7796e+00,  1.6841e+00,  1.7592e+00,  8.8806e-01,\n         3.5501e+00, -1.5417e-01,  1.1845e+00,  4.4052e-01, -9.8483e-01,\n        -1.4193e+00, -2.6208e+00,  1.2208e+00, -1.1315e+00,  3.3494e-01,\n         3.6034e-01, -2.5285e+00, -7.8882e-01,  2.3313e+00, -5.6662e-01,\n         3.8081e-01, -2.1388e+00,  1.0505e+00, -5.0555e+00,  1.5860e+00,\n        -7.0210e-01,  3.4588e+00, -7.7145e+00, -2.5656e+00, -4.1447e-01,\n         1.6298e+00, -3.3544e+00, -3.5672e+00, -9.2165e-01, -1.6571e+00,\n         4.8018e+00, -6.6727e-01,  4.0046e+00, -4.6979e+00, -9.1355e-01,\n        -2.4762e+00,  3.4751e+00,  8.3189e-01, -1.7558e+00,  2.1527e+00,\n         5.4884e-01,  6.9167e+00, -3.6467e+00, -3.1437e+00, -4.2019e-01,\n         4.1283e-01, -2.6552e+00,  8.3868e-01, -4.2907e-01, -2.0446e-01,\n        -4.6957e-01, -2.1834e+00, -3.7623e-01, -8.9141e-01,  1.6667e+00,\n         2.1786e-01,  2.6001e+00,  1.0687e+00,  7.5777e-01,  1.7174e-01,\n        -1.4710e+00,  2.4633e+00, -9.1192e-01,  2.1838e-02, -3.8835e+00,\n         3.1880e+00, -4.1604e-01, -5.0055e-01, -2.5285e+00,  9.7178e-01,\n         9.8181e-01, -6.6536e+00,  1.8998e+00,  3.0896e+00, -1.2525e+00,\n        -7.2639e-01, -1.9906e+00, -4.8464e-02, -2.0723e+00,  6.5498e-01,\n         3.5971e+00, -3.9449e+00,  1.3102e+00, -2.9706e+00,  2.8577e+00,\n        -3.5199e+00,  2.0650e+00, -5.5191e+00, -1.0296e+00, -2.7896e+00,\n         1.2004e+00,  4.0013e+00,  1.7191e+00,  3.3222e+00,  1.6079e+00,\n         2.2419e+00,  1.2770e-01,  1.6512e+00, -1.5860e+00, -7.8163e-01,\n         2.1875e+00, -2.3125e-01, -3.2025e+00,  1.2858e-01,  2.3908e+00,\n         1.7743e+00, -8.9007e-01, -1.5624e+00, -3.3389e+00,  1.1713e-01,\n         1.5986e+00,  7.9414e-01, -5.2136e-01,  8.2685e+00,  1.5645e+00,\n         1.2128e+00, -1.3926e+00, -2.7770e+00, -7.3394e-01,  1.0291e+00,\n        -1.3788e+00,  3.3041e+00,  5.0251e-01, -2.0048e+00,  3.7143e+00,\n        -1.4210e+00, -3.4421e+00,  9.9944e-01, -2.5297e+00, -1.4038e+00,\n        -3.7786e-01, -1.5796e+00,  1.7520e+00,  1.9520e+00, -5.2755e+00,\n        -3.5026e+00,  4.2346e-02,  9.8672e-01, -1.8672e+00, -2.7622e+00,\n        -1.1358e+00, -5.2828e-01, -4.2557e-02,  1.7487e-01,  3.2390e+00,\n         2.7844e+00, -1.2396e+00, -2.5141e+00,  8.7780e-02, -2.4966e+00,\n        -4.3721e-01,  3.3705e+00,  2.1920e+00,  3.8160e+00,  3.3360e+00,\n        -1.7692e+00,  7.6428e+00,  2.5814e+00,  2.7244e+00, -1.3984e+00,\n        -1.0237e+00, -5.3888e+00, -1.4169e-01,  1.7292e+00, -2.0069e+00,\n         1.6450e+00, -2.9804e+00,  6.8182e-03, -2.1767e+00, -2.9492e-01,\n        -1.6504e+00, -2.0288e+00, -1.7733e+00, -4.6154e-01, -2.1621e+00,\n         1.9726e+00, -8.3340e-01,  1.1298e+00,  1.4651e+00,  1.3711e-01,\n        -1.0181e+00, -1.3043e+00,  2.4112e+00,  2.5805e+00, -9.1143e-01,\n         7.4372e-01, -1.9868e+00, -4.5469e+00, -1.2352e+00, -6.0758e-01,\n        -2.4562e-01, -7.1458e-01,  1.2242e+00,  4.3158e-01, -1.8799e+00,\n         3.1438e+00,  1.3864e+00, -1.3490e+00, -2.0083e+00,  4.3331e-01,\n        -1.4570e+00,  5.2684e+00,  3.4112e+00, -8.8133e-02,  2.9432e+00,\n        -1.7988e+00, -5.4117e+00,  9.8254e-01,  1.0903e+00,  2.6092e+00,\n        -9.3854e-01,  6.8563e-01,  4.4855e+00, -6.8601e-01, -3.8211e-01,\n         3.0179e+00, -5.7160e-02,  5.3739e-02, -3.8198e+00, -3.1104e-01,\n        -6.5229e-01, -1.5640e+00, -3.0974e+00, -9.9994e-01,  4.0769e+00,\n         5.2354e-01, -1.1748e+00, -1.6108e+00, -3.3907e+00,  2.5584e+00,\n         3.4511e+00,  7.2153e-01, -6.3189e-01,  6.0800e-03, -2.9036e-01,\n        -1.9907e+00,  5.0088e-01,  8.7195e-01,  1.1937e+00,  1.6852e+00,\n         1.6982e-01,  2.2475e+00, -4.9811e-01,  3.1667e+00,  4.1837e+00,\n        -3.3268e+00, -2.4721e+00, -1.7605e+00,  2.7772e+00,  2.5869e+00,\n        -6.0387e-01,  2.4680e+00,  1.2774e+00, -6.2009e-01,  4.0067e-02,\n         1.9600e-01,  2.8381e-01,  6.3366e+00, -8.4487e-01, -1.2907e+00,\n         7.3615e-01, -1.1590e+00, -1.6424e+00,  1.6922e+00, -8.3723e-01,\n         1.9354e+00,  7.7306e-01,  5.4444e+00,  3.7660e+00, -3.3192e-01,\n         2.5055e+00,  9.4292e-01, -1.0279e+00, -3.6788e+00, -3.4192e+00,\n         6.3304e-01,  2.0381e+00, -1.4330e+00, -2.0233e+01,  6.0205e+00,\n         4.4119e-01, -2.6730e+00,  4.6830e-01, -1.2010e+00, -1.0689e-01,\n        -1.2677e+00, -4.1449e+00,  1.1956e+00, -4.2466e+00, -3.3496e+00,\n         1.6204e+00, -4.8541e-01, -7.9446e-01, -4.0161e+00,  2.5699e-01,\n         1.7856e+00,  4.4354e-01, -1.1503e+00, -1.7690e+00, -1.1199e+00,\n        -9.8018e-01,  2.7701e+00,  2.5429e+00,  3.2512e+00, -1.4247e+00,\n        -1.6259e+00,  7.2887e-01,  1.8703e+00,  6.4776e-01,  3.2180e-01,\n        -7.2597e-01, -3.7175e+00, -8.5630e-01, -1.9535e+00, -1.5240e+00,\n        -1.5539e+00,  2.2183e+00, -2.4517e+00, -1.3617e-01,  2.2560e+00,\n        -3.4751e+00,  1.3650e+00,  3.2119e+00, -9.6664e-01, -7.6485e-01,\n         1.7122e+00, -1.2801e+00,  2.0852e+00,  2.8767e+00, -3.8950e+00,\n         9.8113e-01,  1.7242e-01,  3.4495e-01,  1.4859e+00, -5.5852e-01,\n         6.7136e-01,  2.6633e+00, -5.9579e-01, -3.0000e+00,  7.5514e-01,\n        -5.4790e-01, -7.5671e-01, -1.2133e+00, -8.6254e-01, -5.0327e+00,\n        -1.1661e+00, -7.1285e-01, -1.6948e+00, -2.9164e+00,  1.0638e+00,\n        -7.2627e-01, -9.7431e+00, -1.7422e+00, -6.0149e-01,  3.5752e+00,\n        -3.9161e+00, -3.8188e+00,  8.0948e-01,  3.3330e+00, -4.5769e-01,\n         1.9656e+00, -1.1025e+00,  2.1057e+00,  2.1082e+00, -2.1407e+00,\n         2.3814e+00, -4.8050e+00, -4.8265e-01,  3.3563e+00,  6.3892e+00,\n         1.1531e+00, -3.3831e+00,  5.0091e-01,  2.5013e+00, -2.7246e+00,\n         4.0183e-01,  2.1308e-01,  8.4656e-01,  6.3941e-01,  4.2848e+00,\n         2.2941e+00, -3.1940e-02, -1.6549e+00, -2.3927e+00,  5.9590e-01,\n        -1.1219e+00, -5.6222e+00,  6.0613e+00,  1.9667e+00, -3.2507e+00,\n         4.7726e+00, -1.0224e+00,  1.1413e+00,  2.0135e+00,  3.6813e-01,\n        -2.8966e+00,  1.2883e+00, -2.0610e+00, -4.0109e+00,  1.5047e-01,\n        -2.6169e+00, -4.6168e+00,  7.6136e-01, -1.8633e-01,  2.6012e+00,\n        -1.6138e+00, -1.5483e+00, -2.4207e+00,  2.7282e+00, -2.2955e+00,\n        -1.4433e+00,  4.2703e-01, -7.4109e-03, -8.4425e-01,  3.8539e+00,\n        -2.0642e+00, -1.8538e+00,  8.0594e-01,  1.4825e+00, -1.0588e+00,\n         9.6762e-01, -1.4310e+00, -5.7655e-01, -2.3115e+00, -1.9844e+00,\n         1.3900e-01,  4.7264e-01, -8.5531e-01, -2.1143e+00, -5.3837e-01,\n         1.9715e+00, -2.6315e+00,  1.7716e+00,  4.7152e+00,  4.3914e+00,\n        -1.4019e+00, -3.8911e+00, -6.1166e-01,  1.3671e+00, -2.1527e+00,\n         2.3419e+00, -3.1465e-01, -9.0002e+00, -1.0389e+00, -5.3536e+00,\n        -2.4695e+00, -9.1647e-01,  2.0877e+00,  1.8750e+00, -1.1232e+00,\n        -1.2421e+00,  2.6287e+00, -4.1496e-01,  8.8053e-01,  1.7962e+00,\n        -3.7740e+00,  1.0248e-02,  2.9005e-01, -1.7473e+00,  3.4708e+00,\n         2.6755e+00, -2.1651e+00,  1.0002e-01,  2.0046e-01,  8.6248e-01,\n         3.0905e+00, -6.6032e-01,  1.8207e-01, -6.0543e-01,  1.2471e+00,\n        -2.0084e-01,  1.1996e+00, -1.1059e+00, -2.7855e+00, -4.2053e-01,\n         1.7112e+00, -1.2885e+00,  1.3230e-01, -2.9591e+00,  1.7663e+00,\n        -1.1734e+00, -2.7677e+00,  9.2257e-01,  1.1600e+00,  1.5473e+00,\n         1.5704e+00, -2.3533e+00,  3.4406e+00, -5.2345e+00,  1.2555e+00,\n        -5.5496e+00, -1.0637e+00,  1.1390e+00, -1.7320e+00,  1.7036e+00,\n        -2.1839e-01, -2.4290e+00, -1.4675e+00,  2.1270e+00,  1.6522e+00,\n        -1.2079e+00, -6.3648e-01, -3.2227e+00,  2.4228e-01,  2.4565e+00,\n         1.0244e+00, -6.3832e-01,  6.8011e-01, -1.4649e+00, -9.7016e-01,\n        -5.2119e-01, -1.7501e-01, -6.0749e-01, -1.2182e+00, -2.6093e+00,\n        -7.3388e+00,  1.8075e-02, -1.3027e+00, -1.4081e+00,  1.8631e+00,\n         4.8133e-01, -1.1803e+00,  2.4576e-01,  4.0584e+00,  3.9418e+00,\n         2.6962e+00,  1.7626e+00,  1.0835e+00,  8.8053e-01, -1.7952e+00,\n         1.3275e+00, -1.2220e+00, -3.4569e+00,  4.4089e+00, -3.1452e-01,\n         3.0937e-01, -8.6750e-01,  2.6437e+00,  1.2257e+00, -2.4544e+00,\n        -7.8743e-01,  1.4993e+00,  1.9859e+00,  7.6927e-01, -5.7185e-01,\n         1.7684e+00,  1.3524e+00, -2.0475e+00,  4.4849e+00, -7.9632e+00,\n         1.1472e+00, -5.7117e-01, -1.5559e+00,  2.8032e+00, -3.4916e+00,\n        -4.9815e+00,  2.3348e+00, -3.4906e-01, -2.1567e+00,  4.9153e-02,\n         2.4575e+00,  2.5525e-01,  1.2323e+00, -1.2431e+00, -2.8267e+00,\n         4.1913e-01, -1.0303e-01, -4.9398e+00,  3.5787e-01,  1.1214e+00,\n        -6.9623e-02,  3.9031e-01, -2.5588e+00,  3.4427e+00,  1.8091e-01,\n         2.1023e+00,  8.3190e-01,  2.0076e+00,  1.5292e+00, -1.7036e+00,\n         3.3937e+00,  7.4799e-01,  2.0258e+00,  2.4239e+00, -9.2988e-01,\n        -1.9650e+00, -6.6456e-01, -1.9439e+00, -5.8781e-01, -5.2827e+00,\n         1.8430e+00,  1.3171e+00, -4.3418e+00,  1.4150e+00, -9.5073e-02,\n        -1.9298e+00, -3.7925e+00,  4.0830e-01, -1.0552e+00,  1.5149e+00,\n         8.1669e-01,  2.5037e+00, -1.0279e+00,  8.7157e-01,  9.2616e-01,\n        -7.5304e-01,  2.2240e+00, -1.7870e-02, -2.9298e+00,  3.1899e+00,\n        -2.8126e+00, -4.3576e-01,  2.2713e+00,  4.9861e-01, -3.5130e+00,\n        -3.2258e+00,  1.1180e+00, -1.3485e+00,  7.2030e-02, -1.9337e+00,\n         4.7428e-01,  6.8527e+00,  2.2437e-01,  3.5916e-01, -2.4048e+00,\n        -1.3963e+00,  1.0802e+00,  3.1457e+00, -6.6196e-01, -3.0102e-01,\n        -2.4358e+00, -5.1050e+00,  2.8838e+00,  1.0038e+00,  1.4167e+00,\n        -1.1728e+00, -1.2216e+00,  7.3839e-01, -1.8901e+00, -1.6966e+00,\n         9.1582e-01, -3.2970e-01, -1.1857e+00,  2.2351e+00, -2.1246e+00,\n        -3.4292e+00,  1.0576e+00, -1.0933e+00, -2.7436e+00, -7.1750e-01,\n         3.9852e+00,  2.6084e+00,  1.9245e+00,  2.7085e+00, -5.7127e+00,\n         4.5873e+00,  1.8541e+00, -3.4734e+00, -1.3353e+00, -2.7261e+00,\n        -3.8192e-01, -1.2524e+00, -1.8546e+00, -1.3269e+00,  2.1771e+00,\n         3.7445e-01, -3.8785e-01, -9.0893e-01,  4.0856e+00, -3.4624e-01,\n         5.0509e-01,  1.2236e+00,  2.6280e+00, -4.1379e-01,  1.3547e+00,\n         2.7384e+00,  3.8214e-01,  6.9528e-01,  2.5420e+00, -3.8014e+00,\n         2.2631e+00, -2.9040e+00, -4.6305e-01,  5.0079e-01,  2.7726e+00,\n        -1.8527e-01, -1.1183e+00,  2.5646e+00, -1.6374e+00, -2.8144e+00,\n        -2.0675e+00,  3.1022e+00, -3.2574e+00, -2.4176e+00, -2.3263e-03,\n         2.8414e+00, -2.1198e+00,  5.7505e-01,  3.1322e-01, -3.8384e-01,\n        -2.7661e-01, -2.9821e+00, -1.9607e+00,  2.6249e+00, -1.4066e+00,\n        -2.2914e+00,  9.9390e-02,  2.7787e+00, -2.3181e+00,  1.5327e-01,\n         3.2065e+00,  4.6407e+00, -1.3823e+00, -2.0390e+00,  1.0706e-01,\n         3.4720e+00, -2.2642e+00,  4.3471e-01,  4.6368e+00,  4.5966e-01,\n         5.0905e-02,  3.2043e+00,  7.0683e-01,  5.2888e-01, -6.1644e-02,\n        -1.7329e+00, -2.5348e-01,  5.0440e+00, -1.0040e+00, -5.2070e-01,\n        -2.1534e+00,  7.8875e-04, -1.9559e+00, -3.5153e+00,  1.3571e-01,\n         5.9728e-01, -2.3119e-01,  1.1103e+00])"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# examine one of the bank tokens encoding in its entirety (768 values)\n",
    "token_vecs_sum[6] # bank vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.945675253868103"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# \"bank robber\" vs \"bank vault\" \n",
    "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
    "same_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6797333359718323"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# \"bank robber\" vs \"river bank\" \n",
    "\n",
    "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
    "diff_bank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda9717ab7b2b12490f80fe877ebbefb4d0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}